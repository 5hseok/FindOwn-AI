{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "# models 폴더가 존재하지 않는다면 git clone으로 models repository를 다운로드 받습니다.\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "  while \"models\" in pathlib.Path.cwd().parts:\n",
    "    os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "  !git clone https://github.com/tensorflow/models\n",
    "  %cd models\n",
    "  !git reset --hard d7ce106b8ea449cc629569ca43a95e55a18807fa  # 안정적인 version의 commit으로 reset\n",
    "  %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "������ ��θ� ã�� �� �����ϴ�.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Directory '.' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow Object Detection API를 설치합니다.\n",
    "# Reference : https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md\n",
    "!cd models/research/protoc object_detection/protos/*.proto --python_out=.cp object_detection/packages/tf2/setup.py .\n",
    "!python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'object_detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DGU_ICE\\FindOwn\\Image_Search\\Image_Search.ipynb 셀 3\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DGU_ICE/FindOwn/Image_Search/Image_Search.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image, ImageDraw, ImageFont\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DGU_ICE/FindOwn/Image_Search/Image_Search.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/DGU_ICE/FindOwn/Image_Search/Image_Search.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mobject_detection\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m label_map_util\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DGU_ICE/FindOwn/Image_Search/Image_Search.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mobject_detection\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m config_util\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DGU_ICE/FindOwn/Image_Search/Image_Search.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mobject_detection\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m visualization_utils \u001b[39mas\u001b[39;00m viz_utils\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'object_detection'"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path 경로에서 이미지를 읽어서 numpy array 형태로 반환합니다.\n",
    "def load_image_into_numpy_array(path):\n",
    "  \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "  Puts image into numpy array to feed into tensorflow graph.\n",
    "  Note that by convention we put it into a numpy array with shape\n",
    "  (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "  Args:\n",
    "    path: the file path to the image\n",
    "\n",
    "  Returns:\n",
    "    uint8 numpy array with shape (img_height, img_width, 3)\n",
    "  \"\"\"\n",
    "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "  image = Image.open(BytesIO(img_data))\n",
    "  (im_width, im_height) = image.size\n",
    "\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faster r-cnn 모델을 불러옵니다.\n",
    "model_name = 'faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tar: Error opening archive: Failed to open 'faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8.tar.gz'\n",
      "'mv'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n"
     ]
    }
   ],
   "source": [
    "# ms coco dataset에 학습된 fasterrcnn의 checkpoint 파일을 다운로드하고 압축을 풉니다.\n",
    "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8.tar.gz\n",
    "!tar -xf faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8.tar.gz\n",
    "# 해당 checkpoint 파일을 models/research/object_detection/test_data/ 경로로 옮깁니다.\n",
    "!mv faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8/checkpoint models/research/object_detection/test_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config_util' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DGU_ICE\\FindOwn\\Image_Search\\Image_Search.ipynb 셀 7\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DGU_ICE/FindOwn/Image_Search/Image_Search.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmodels/research/object_detection/test_data/checkpoint/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DGU_ICE/FindOwn/Image_Search/Image_Search.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# config파일을 이용해서 모델 인스턴스를 생성합니다.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/DGU_ICE/FindOwn/Image_Search/Image_Search.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m configs \u001b[39m=\u001b[39m config_util\u001b[39m.\u001b[39mget_configs_from_pipeline_file(pipeline_config)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DGU_ICE/FindOwn/Image_Search/Image_Search.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model_config \u001b[39m=\u001b[39m configs[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DGU_ICE/FindOwn/Image_Search/Image_Search.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m detection_model \u001b[39m=\u001b[39m model_builder\u001b[39m.\u001b[39mbuild(model_config\u001b[39m=\u001b[39mmodel_config, is_training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'config_util' is not defined"
     ]
    }
   ],
   "source": [
    "# config 파일과 checkpoint 파일의 경로를 설정합니다.\n",
    "pipeline_config = os.path.join('models/research/object_detection/configs/tf2/', model_name + '.config')\n",
    "model_dir = 'models/research/object_detection/test_data/checkpoint/'\n",
    "\n",
    "# config파일을 이용해서 모델 인스턴스를 생성합니다.\n",
    "configs = config.util.get_configs_from_pipeline_file(pipeline_config)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "\n",
    "# checkpoint 파일로부터 파라미터를 복원합니다.\n",
    "ckpt = tf.compat.v2.train.Checkpoint(\n",
    "      model=detection_model)\n",
    "ckpt.restore(os.path.join(model_dir, 'ckpt-0')).expect_partial()\n",
    "\n",
    "# model의 예측 결과를 받아옵니다.\n",
    "def get_model_detection_function(model):\n",
    "  \"\"\"Get a tf.function for detection.\"\"\"\n",
    "\n",
    "  def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = model.preprocess(image)\n",
    "    prediction_dict = model.predict(image, shapes)\n",
    "    detections = model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
    "\n",
    "  return detect_fn\n",
    "\n",
    "detect_fn = get_model_detection_function(detection_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms coco 레이블들을 읽어옵니다.\n",
    "LABEL_MAP_PATH = 'models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "\n",
    "label_map_path = LABEL_MAP_PATH\n",
    "label_map = label_map_util.load_labelmap(label_map_path)\n",
    "categories = label_map_util.convert_label_map_to_categories(\n",
    "    label_map,\n",
    "    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n",
    "    use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'models/research/object_detection/test_images/'\n",
    "image_path = os.path.join(image_dir, 'image1.jpg')\n",
    "image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "# 이미지에 대한 예측을 수행합니다.\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "# confidence threshold를 0.7로 높여서 더 정확한 Bounding box 출력결과만 화면에 그립니다.\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np_with_detections,\n",
    "      detections['detection_boxes'][0].numpy(),\n",
    "      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
    "      detections['detection_scores'][0].numpy(),\n",
    "      category_index,\n",
    "      use_normalized_coordinates=True,\n",
    "      max_boxes_to_draw=200,\n",
    "      min_score_thresh=.70,\n",
    "      agnostic_mode=False\n",
    "      )\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(image_np_with_detections)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
