{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "#전체 이미지 DB에 있는 이미지들에서 유사도를 전부 측정한다.\n",
    "def create_feature_extractor(model, return_nodes=None):\n",
    "    if return_nodes is None:\n",
    "        return_nodes = {'avgpool': 'avgpool'}\n",
    "\n",
    "    return_nodes_output = {}\n",
    "    for name, module in model.named_modules():\n",
    "        if name in return_nodes:\n",
    "            return_nodes_output[name] = module\n",
    "\n",
    "    return return_nodes_output\n",
    "\n",
    "model = EfficientNet.from_pretrained('efficientnet-b7')\n",
    "model_features = create_feature_extractor(model,return_nodes={'avgpool':'avgpool'})\n",
    "model.eval()    \n",
    "\n",
    "import requests\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "def image_resize(image_url):                #이미지 url로 받아올 때 사용\n",
    "    image = Image.open(requests.get(image_url, stream=True).raw)\n",
    "    rgb_image = image.convert('RGB')\n",
    "    preprocess = T.Compose([\n",
    "        T.Resize(256, interpolation=T.InterpolationMode.BICUBIC),\n",
    "        T.CenterCrop(224),\n",
    "        T.ToTensor()]\n",
    "    )\n",
    "    return preprocess(rgb_image).unsqueeze(0)\n",
    "\n",
    "\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "\n",
    "def image_resize_local(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Unable to open image. {e}\")\n",
    "        return None\n",
    "\n",
    "    # 이미지 전처리: 크기 조정, 텐서 변환, 정규화\n",
    "    preprocess = Compose([\n",
    "        Resize((224, 224)),\n",
    "        ToTensor(),\n",
    "        Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "    return preprocess(image)\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import torch\n",
    "\n",
    "def is_image_file(filename):\n",
    "    # 파일 확장자 검사\n",
    "    VALID_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')\n",
    "    _, ext = os.path.splitext(filename)\n",
    "    return ext.lower() in VALID_EXTENSIONS\n",
    "\n",
    "def cos_sim(A, B):\n",
    "    return dot(A, B) / (norm(A) * norm(B))\n",
    "\n",
    "def predict(image_path):\n",
    "    resized_image = image_resize_local(image_path)\n",
    "    if resized_image is None:\n",
    "        return None\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image_transformed=resized_image.unsqueeze(0)\n",
    "        predicted_result=model(image_transformed)\n",
    "        image_feature=torch.flatten(predicted_result)\n",
    "    return image_feature.detach().numpy()\n",
    "    \n",
    "\n",
    "root_dir = \"C:\\\\Users\\\\DGU_ICE\\\\FindOwn\\\\ImageDB\\\\Logos\"\n",
    "#자신의 로컬에 있는 Image 파일 주소로 설정할 것.\n",
    "\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# 타겟 이미지 경로\n",
    "target_image_path = \"C:\\\\Users\\\\DGU_ICE\\\\FindOwn\\\\ImageDB\\\\Logos\\\\uefa-champions-league-eps-vector-logo-400x400.png\"\n",
    "\n",
    "# 디렉토리에서 이미지 파일들 찾기\n",
    "image_files = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(root_dir):\n",
    "    for filename in filenames:\n",
    "        if is_image_file(filename):\n",
    "            image_files.append(os.path.join(dirpath, filename))\n",
    "\n",
    "# 각 이미지와 타겟 이미지 간에 코사인 유사도 저장할 리스트 초기화\n",
    "similarities = []\n",
    "\n",
    "import cv2\n",
    "import urllib.request\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# 타겟 이미지 특징 추출\n",
    "def process_image(image_path):\n",
    "    source_embedding = predict(image_path)\n",
    "    if source_embedding is None or target_embedding is None:\n",
    "        return image_path, None\n",
    "    similarity = cos_sim(source_embedding,target_embedding)\n",
    "    return image_path, similarity\n",
    "\n",
    "import time\n",
    "start_time=time.time()\n",
    "target_embedding = predict(target_image_path)\n",
    "\n",
    "# 각 이미지와 타겟 이미지의 유사도 계산\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    results = list(executor.map(process_image, image_files))\n",
    "\n",
    "# 유효한 결과만 저장하고 출력합니다.\n",
    "top_results = []\n",
    "for image_path, similarity in results:\n",
    "    if similarity is not None:\n",
    "        top_results.append((image_path, similarity))\n",
    "    \n",
    "top_results=sorted(top_results, key=lambda x: x[1],reverse=True)[:10]\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"병렬 처리 시간: {elapsed_time}초\")\n",
    "for image_path, similarity in top_results:\n",
    "    print(\"Similarity between\", image_path, \"and target image:\",similarity)\n",
    "\n",
    "\n",
    "# # 유사도의 평균을 계산합니다\n",
    "# average_similarity = sum(similarities) / len(similarities)\n",
    "# print(\"Average similarity: {:.4f}%\".format(round(average_similarity * 100,4)))\n",
    "\n",
    "# import csv\n",
    "# # CSV 파일을 쓰기 모드로 연다.\n",
    "# with open('image_similarity_Top10image.csv', mode='w', newline='') as csv_file:\n",
    "#     csv_writer = csv.writer(csv_file)\n",
    "#     csv_writer.writerow(['Image', 'Target Image', 'Similarity'])\n",
    "\n",
    "#     for image_path, similarity in top_results:\n",
    "#         # 유사도 값을 CSV 파일에 기록한다.\n",
    "#         csv_writer.writerow([image_path, target_image_path, similarity * 100])\n",
    "\n",
    "# 생성할 subplot의 행과 열 계산\n",
    "n_rows = 3\n",
    "n_cols = 4\n",
    "\n",
    "# 하나의 figure에서 타겟 이미지와 top-10 이미지 출력\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# 타겟 이미지 출력\n",
    "image = cv2.imread(target_image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 1)\n",
    "plt.title(\"Target Image\")\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "top10_image_list=[]\n",
    "# 상위 10개 이미지 출력\n",
    "for i, (image_path, similarity) in enumerate(top_results):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    top10_image_list.append(image_path)\n",
    "    plt.subplot(n_rows, n_cols, i + 2)\n",
    "    plt.title(f\"Image {i + 1} (similarity: {similarity * 100:.2f}%)\")\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DGU_ICE\\FindOwn\\Image_Search\\Image_Search_TotalImage.ipynb 셀 2\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DGU_ICE/FindOwn/Image_Search/Image_Search_TotalImage.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DGU_ICE/FindOwn/Image_Search/Image_Search_TotalImage.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Load the model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/DGU_ICE/FindOwn/Image_Search/Image_Search_TotalImage.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mhttps://tfhub.dev/tensorflow/efficientdet/d7/1\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DGU_ICE/FindOwn/Image_Search/Image_Search_TotalImage.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Load image and preprocess it\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DGU_ICE/FindOwn/Image_Search/Image_Search_TotalImage.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m image \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mdecode_jpeg(tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mread_file(target_image_path))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_hub\\module_v2.py:120\u001b[0m, in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m    117\u001b[0m   obj \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39mload_v2(\n\u001b[0;32m    118\u001b[0m       module_path, tags\u001b[39m=\u001b[39mtags, options\u001b[39m=\u001b[39moptions)\n\u001b[0;32m    119\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m   obj \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49msaved_model\u001b[39m.\u001b[39;49mload_v2(module_path, tags\u001b[39m=\u001b[39;49mtags)\n\u001b[0;32m    121\u001b[0m obj\u001b[39m.\u001b[39m_is_hub_module_v1 \u001b[39m=\u001b[39m is_hub_module_v1  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\saved_model\\load.py:836\u001b[0m, in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    834\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(export_dir, os\u001b[39m.\u001b[39mPathLike):\n\u001b[0;32m    835\u001b[0m   export_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(export_dir)\n\u001b[1;32m--> 836\u001b[0m result \u001b[39m=\u001b[39m load_partial(export_dir, \u001b[39mNone\u001b[39;49;00m, tags, options)[\u001b[39m\"\u001b[39m\u001b[39mroot\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    837\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\saved_model\\load.py:966\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    964\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39minit_scope():\n\u001b[0;32m    965\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 966\u001b[0m     loader \u001b[39m=\u001b[39m Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0;32m    967\u001b[0m                     ckpt_options, options, filters)\n\u001b[0;32m    968\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mNotFoundError \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    969\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    970\u001b[0m         \u001b[39mstr\u001b[39m(err) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m You may be trying to load on a different device \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    971\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfrom the computational device. Consider setting the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    972\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    973\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto the io_device such as \u001b[39m\u001b[39m'\u001b[39m\u001b[39m/job:localhost\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\saved_model\\load.py:157\u001b[0m, in \u001b[0;36mLoader.__init__\u001b[1;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_proto \u001b[39m=\u001b[39m object_graph_proto\n\u001b[0;32m    155\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_export_dir \u001b[39m=\u001b[39m export_dir\n\u001b[0;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_functions \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 157\u001b[0m     function_deserialization\u001b[39m.\u001b[39;49mload_function_def_library(\n\u001b[0;32m    158\u001b[0m         library\u001b[39m=\u001b[39;49mmeta_graph\u001b[39m.\u001b[39;49mgraph_def\u001b[39m.\u001b[39;49mlibrary,\n\u001b[0;32m    159\u001b[0m         saved_object_graph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_proto,\n\u001b[0;32m    160\u001b[0m         wrapper_function\u001b[39m=\u001b[39;49m_WrapperFunction))\n\u001b[0;32m    161\u001b[0m \u001b[39m# Store a set of all concrete functions that have been set up with\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39m# captures.\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restored_concrete_functions \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:381\u001b[0m, in \u001b[0;36mload_function_def_library\u001b[1;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001b[0m\n\u001b[0;32m    379\u001b[0m function_deps \u001b[39m=\u001b[39m {}\n\u001b[0;32m    380\u001b[0m \u001b[39mfor\u001b[39;00m fdef \u001b[39min\u001b[39;00m library\u001b[39m.\u001b[39mfunction:\n\u001b[1;32m--> 381\u001b[0m   function_deps[fdef\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname] \u001b[39m=\u001b[39m _list_function_deps(\n\u001b[0;32m    382\u001b[0m       fdef, library_function_names, library_gradient_names)\n\u001b[0;32m    384\u001b[0m loaded_gradients \u001b[39m=\u001b[39m {}\n\u001b[0;32m    385\u001b[0m \u001b[39mfor\u001b[39;00m fdef \u001b[39min\u001b[39;00m _sort_function_defs(library, function_deps):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:636\u001b[0m, in \u001b[0;36m_list_function_deps\u001b[1;34m(fdef, library_function_names, library_gradient_names)\u001b[0m\n\u001b[0;32m    634\u001b[0m         deps\u001b[39m.\u001b[39madd(attr_value\u001b[39m.\u001b[39mfunc\u001b[39m.\u001b[39mname)\n\u001b[0;32m    635\u001b[0m       \u001b[39melif\u001b[39;00m attr_value\u001b[39m.\u001b[39mWhichOneof(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlist\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 636\u001b[0m         \u001b[39mfor\u001b[39;00m fn \u001b[39min\u001b[39;00m attr_value\u001b[39m.\u001b[39;49mlist\u001b[39m.\u001b[39mfunc:\n\u001b[0;32m    637\u001b[0m           deps\u001b[39m.\u001b[39madd(fn\u001b[39m.\u001b[39mname)\n\u001b[0;32m    639\u001b[0m \u001b[39mreturn\u001b[39;00m deps\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Load the model\n",
    "model = hub.load(\"https://tfhub.dev/tensorflow/efficientdet/d7/1\")\n",
    "\n",
    "# Load image and preprocess it\n",
    "image = tf.image.decode_jpeg(tf.io.read_file(target_image_path))\n",
    "if image.shape[-1] != 3:\n",
    "    if image.shape[-1] == 1:\n",
    "        # Convert grayscale to RGB\n",
    "        image = tf.image.grayscale_to_rgb(image)\n",
    "    elif image.shape[-1] == 4:\n",
    "        # Convert RGBA to RGB by discarding the alpha channel\n",
    "        image = image[..., :3]\n",
    "        \n",
    "image = tf.image.resize(image, [224, 224])\n",
    "image = tf.cast(image, dtype=tf.uint8)\n",
    "\n",
    "image = image[tf.newaxis, ...] # Add batch dimension and normalize\n",
    "\n",
    "# Run detection\n",
    "detections = model(image)\n",
    "\n",
    "with open('coco-labels-2014_2017.txt','r') as f:\n",
    "    mscoco_labels = [line.rstrip() for line in f]\n",
    "\n",
    "# Print detected classes and bounding boxes\n",
    "check = False\n",
    "target_image_label = []\n",
    "for i in range(int(detections['num_detections'])):\n",
    "    score = detections['detection_scores'][0][i]\n",
    "    \n",
    "    # Only consider detections with a confidence score of at least 0.5\n",
    "    if score >= 0.4:\n",
    "        class_id = int(detections['detection_classes'][0][i])\n",
    "        box = detections['detection_boxes'][0][i]\n",
    "\n",
    "        label = mscoco_labels[class_id]\n",
    "        check = True\n",
    "        print(f\"Detected class: {label}\")\n",
    "        target_image_label.append(label)\n",
    "        print(\"Detection score :\", score.numpy())\n",
    "if check == False:\n",
    "    print(\"No object detected\")\n",
    "\n",
    "##############top 10 images object detected##############\n",
    "final_labels=[]\n",
    "\n",
    "for i in range(len(top10_image_list)):\n",
    "    image = tf.image.decode_jpeg(tf.io.read_file(top10_image_list[i]))\n",
    "    if image.shape[-1] != 3:\n",
    "        if image.shape[-1] == 1:\n",
    "            # Convert grayscale to RGB\n",
    "            image = tf.image.grayscale_to_rgb(image)\n",
    "        elif image.shape[-1] == 4:\n",
    "            # Convert RGBA to RGB by discarding the alpha channel\n",
    "            image = image[..., :3]\n",
    "            \n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = tf.cast(image, dtype=tf.uint8)\n",
    "\n",
    "    image = image[tf.newaxis, ...] # Add batch dimension and normalize\n",
    "\n",
    "    # Run detection\n",
    "    detections = model(image)\n",
    "    check = False\n",
    "    for i in range(int(detections['num_detections'])):\n",
    "        score = detections['detection_scores'][0][i]\n",
    "        \n",
    "        # Only consider detections with a confidence score of at least 0.5\n",
    "        if score >= 0.4:\n",
    "            class_id = int(detections['detection_classes'][0][i])\n",
    "            box = detections['detection_boxes'][0][i]\n",
    "            label = mscoco_labels[class_id]\n",
    "            check = True\n",
    "            print(f\"Detected class\",i,\":\" ,{label})\n",
    "            final_labels.append(label)\n",
    "            print(\"Detection score :\", score.numpy())\n",
    "    if check == False:\n",
    "        print(i,\"image has not object\")\n",
    "    \n",
    "endpoint = 0\n",
    "final_result_images_index = []\n",
    "for i in range(len(final_labels)):\n",
    "    if final_labels[i] in target_image_label:\n",
    "        print(final_labels[i],i)\n",
    "        final_result_images_index.append(i)\n",
    "    else:\n",
    "        endpoint +=1\n",
    "if endpoint == len(final_labels):\n",
    "    print(\"no images\")\n",
    "    \n",
    "plt.imshow(cv2.imread(target_image_path))\n",
    "for i in range(len(final_result_images_index)):\n",
    "    plt.imshow(cv2.imread(top10_image_list[final_result_images_index]))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
